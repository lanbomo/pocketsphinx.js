<!DOCTYPE html>
<html>
  <head>
    <meta charset='utf-8'>
    <meta http-equiv="X-UA-Compatible" content="chrome=1">
    <meta name="viewport" content="width=device-width, initial-scale=1, maximum-scale=1">
    <link href='https://fonts.googleapis.com/css?family=Architects+Daughter' rel='stylesheet' type='text/css'>
    <link rel="stylesheet" type="text/css" href="stylesheets/stylesheet.css" media="screen" />
    <link rel="stylesheet" type="text/css" href="stylesheets/pygment_trac.css" media="screen" />
    <link rel="stylesheet" type="text/css" href="stylesheets/print.css" media="print" />

    <!--[if lt IE 9]>
    <script src="//html5shiv.googlecode.com/svn/trunk/html5.js"></script>
    <![endif]-->

    <title>Pocketsphinx.js Live Demo for Chinese</title>
  </head>

  <body>
    <header>
      <div class="inner">
        <a href="/"><h1>Pocketsphinx.js</h1></a>
        <h2>Speech recognition in JavaScript</h2>
        <a href="https://github.com/syl22-00/pocketsphinx.js" class="button"><small>View project on</small>GitHub</a>
      </div>
    </header>
    
    <div id="content-wrapper">
      <div class="inner clearfix">
        <section id="main-content">
          <h1>
	    <a name="pocketsphinxjs-live-demo" class="anchor" href="#pocketsphinxjs-live-demo"><span class="octicon octicon-link"></span></a>Pocketsphinx.js Live Demo for Mandarin Chinese.</h1>
	  <p>This demo works on Chrome and Firefox (25+) with the Web Audio API.</p>
	  <h1>Usage</h1>
	  <p>Allow your browser to access the microphone, select a <a href="#grammar-definitions">grammar</a>, press <em>Start</em>, and start speaking.</p>
	  <select id="grammars"></select>
	  <button id="startBtn">Start</button>
	  <button id="stopBtn">Stop</button>
	  <span id="recording-indicator" style="border-radius: 10px; -moz-border-radius: 10px; -webkit-border-radius: 10px; width: 20px; height: 20px; background: red;"></span>
	  <h1>Recognition Output</h1>
	  <div id="output" class="reco-output" style="height:100px;" >
	  </div>
	  <h1>Status</h1>
	  <div class="reco-output" id="current-status">Loading page</div>
	  
	  <h1><a class="anchor" name="grammar-definitions">Grammars</a></h1>
	  <dl>
	    <dt>Chinese Greetings</dt>
	    <dd>Say some of the following greetings: <code>你好</code>, <code>你好吗</code>, <code>再见</code>, <code>欢迎</code>, <code>谢谢</code>, <code>明天见</code>.</dd>
	  </dl>
        </section>

        <aside id="sidebar">
          <a href="https://github.com/syl22-00/pocketsphinx.js/zipball/master" class="button">
            <small>Download</small>
            .zip file
          </a>
          <a href="https://github.com/syl22-00/pocketsphinx.js/tarball/master" class="button">
            <small>Download</small>
            .tar.gz file
          </a>
	  <div class="g-page" data-width="273" data-href="//plus.google.com/116277782074809894586" data-layout="landscape" data-showcoverphoto="false" data-rel="publisher"></div>
	  <br/>
          <p class="repo-owner"><a href="https://github.com/syl22-00/pocketsphinx.js"></a> is maintained by <a href="https://github.com/syl22-00">syl22-00</a>.</p>

          <p>This page was generated by <a href="pages.github.com">GitHub Pages</a> using the Architect theme by <a href="http://twitter.com/jasonlong">Jason Long</a>.</p>
        </aside>
      </div>
    </div>
    <script>




      var recognizer, recorder, callbackManager, audio_context;
      var isRecorderReady = isRecognizerReady = false;
      function postRecognizerJob(message, callback) {
        var msg = message || {};
        if(callbackManager) msg.callbackId = callbackManager.add(callback);
        if (recognizer) recognizer.postMessage(msg);
      };

      function spawnWorker(workerurl, onReady) {
          recognizer = new Worker(workerurl);
          recognizer.onmessage = function(event) {
            onReady(recognizer);
          };
          recognizer.postMessage('pocketsphinx_zh.js');
      };

      function updateHyp(hyp) {
        document.getElementById('output').innerHTML = hyp;
      };

      function updateUI() {
        if (isRecorderReady && isRecognizerReady) startBtn.disabled = stopBtn.disabled = false;
      };

      function updateStatus(newStatus) {
        document.getElementById('current-status').innerHTML += "<br/>" + newStatus;
      };

      function displayRecording(display) {
        if (display) document.getElementById('recording-indicator').innerHTML = "&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;";
        else document.getElementById('recording-indicator').innerHTML = "";
      };

      function startUserMedia(stream) {
        var input = audio_context.createMediaStreamSource(stream);
        window.firefox_audio_hack = input;
        // Notice that for this Chinese acoustic model, audio must be at 8kHz, so we should
        // request it from the recorder
        var audioRecorderConfig = {
               errorCallback: function(x) {updateStatus("Error from recorder: " + x);},
               outputSampleRate: 8000
        };
        recorder = new AudioRecorder(input, audioRecorderConfig);
        // If a recognizer is ready, we pass it to the recorder
        if (recognizer) recorder.consumers = [recognizer];
        isRecorderReady = true;
        updateUI();
        updateStatus("Audio recorder ready");
      };

      var startRecording = function() {
      var id = document.getElementById('grammars').value;
      if (recorder && recorder.start(id)) displayRecording(true);
      };

      var stopRecording = function() {
        recorder && recorder.stop();
        displayRecording(false);
      };

      var recognizerReady = function() {
           updateGrammars();
           isRecognizerReady = true;
           updateUI();
           updateStatus("Recognizer ready");
      };

      var updateGrammars = function() {
        var selectTag = document.getElementById('grammars');
        for (var i = 0 ; i < grammarIds.length ; i++) {
            var newElt = document.createElement('option');
            newElt.value=grammarIds[i].id;
            newElt.innerHTML = grammarIds[i].title;
            selectTag.appendChild(newElt);
        }                          
      };


      var feedGrammar = function(g, index, id) {
        if (id && (grammarIds.length > 0)) grammarIds[0].id = id.id;
        if (index < g.length) {
          grammarIds.unshift({title: g[index].title})
	  postRecognizerJob({command: 'addGrammar', data: g[index].g},
                             function(id) {feedGrammar(grammars, index + 1, {id:id});});
        } else {
          recognizerReady();
        }
      };

      var feedWords = function(words) {
           postRecognizerJob({command: 'addWords', data: words},
                        function() {feedGrammar(grammars, 0);});
      };

      // This initializes the recognizer. When it calls back, we add words
      var initRecognizer = function() {
          // You can pass parameters to the recognizer, such as : {command: 'initialize', data: [["-hmm", "my_model"], ["-fwdflat", "no"]]}
          // Pay attention here to state the sample rate as the default value is 16kHz and this Chinese acoustic model uses 8kHz
          postRecognizerJob({command: 'initialize', data:[["-samprate", "8000"]]},
                            function() {
                                        if (recorder) recorder.consumers = [recognizer];
                                        feedWords(wordList);});
      };

      window.onload = function() {
        if (window.location.protocol != "https:")
          window.location.href = "https:" + window.location.href.substring(window.location.protocol.length);
        updateStatus("Initializing Web Audio and speech recognizer, waiting for approval to access your microphone");
        callbackManager = new CallbackManager();
        spawnWorker("js/recognizer.js", function(worker) {
            worker.onmessage = function(e) {
                if (e.data.hasOwnProperty('id')) {
                  var clb = callbackManager.get(e.data['id']);
                  var data = {};
                  if( e.data.hasOwnProperty('data')) data = e.data.data;
                  if(clb) clb(data);
                }
                if (e.data.hasOwnProperty('hyp')) {
                  var newHyp = e.data.hyp;
                  var newHypChinese = e.data.hyp.split(' ').map(function(x) {return wordListChinese[x];}).join(' ');
                  if (e.data.hasOwnProperty('final') &&  e.data.final) {
                      newHyp = "Final: " + newHyp;
                      newHypChinese = "Final: " + newHypChinese;
                  }
                  updateHyp(newHyp + '<br><br>' + newHypChinese);
                }
                if (e.data.hasOwnProperty('status') && (e.data.status == "error")) {
                  updateStatus("Error in " + e.data.command + " with code " + e.data.code);
                }
            };
            initRecognizer();
        });
        try {
          window.AudioContext = window.AudioContext || window.webkitAudioContext;
          navigator.getUserMedia = navigator.getUserMedia || navigator.webkitGetUserMedia || navigator.mozGetUserMedia;
          window.URL = window.URL || window.webkitURL;
          audio_context = new AudioContext();
        } catch (e) {
          updateStatus("Error initializing Web Audio browser");
        }
        if (navigator.getUserMedia) navigator.getUserMedia({audio: true}, startUserMedia, function(e) {
                                        updateStatus("No live audio input in this browser");
                                    });
        else updateStatus("No web audio support in this browser");

      var startBtn = document.getElementById('startBtn');
      var stopBtn = document.getElementById('stopBtn');
      startBtn.disabled = true;
      stopBtn.disabled = true;
      startBtn.onclick = startRecording;
      stopBtn.onclick = stopRecording;
      };

      // This is the list of words that need to be added to the recognizer
      // This follows the CMU dictionary format and the phone set of the Chinese model
      // These words were taken from model/lm/zh_CN/mandarin_notone.dic
      var wordList = [["lan_bo","l an b o"],["ni_hao","n i h ao"], ["ni_hao_ma", "n i h ao m a"], ["zai_jian", "z ai j ian"], ["huan_ying", "h uan y ing"], ["xie_xie", "x ie x ie"], ["ming_tian_jian", "m ing t ian j ian"]];
      var wordListChinese = {"lan_bo": "蓝博", "ni_hao": "你好", "ni_hao_ma": "你好吗", "zai_jian": "再见", "huan_ying": "欢迎", "xie_xie": "谢谢", "ming_tian_jian": "明天见"};
      var grammarChineseGreetings = {numStates: 1, start: 0, end: 0, transitions: [{from: 0, to: 0, word: "ni_hao"},{from: 0, to: 0, word: "ni_hao_ma"},{from: 0, to: 0, word: "zai_jian"},{from: 0, to: 0, word: "huan_ying"},{from: 0, to: 0, word: "xie_xie"},{from: 0, to: 0, word: "ming_tian_jian"}]};
      var grammars = [{title: "Chinese Greetings", g: grammarChineseGreetings}];
      var grammarIds = [];

    </script>
    
    <script>
      (function(i,s,o,g,r,a,m){i['GoogleAnalyticsObject']=r;i[r]=i[r]||function(){
      (i[r].q=i[r].q||[]).push(arguments)},i[r].l=1*new Date();a=s.createElement(o),
      m=s.getElementsByTagName(o)[0];a.async=1;a.src=g;m.parentNode.insertBefore(a,m)
      })(window,document,'script','//www.google-analytics.com/analytics.js','ga');
      ga('create', 'UA-41771114-1', 'syl22-00.github.io');
      ga('send', 'pageview');
    </script>
    <script src="js/audioRecorder.js"></script>
    <script src="js/callbackManager.js"></script>
    <script type="text/javascript">
      (function() {
      var po = document.createElement('script'); po.type = 'text/javascript'; po.async = true;
      po.src = 'https://apis.google.com/js/plusone.js';
      var s = document.getElementsByTagName('script')[0]; s.parentNode.insertBefore(po, s);
      })();
    </script>

  </body>
</html>
